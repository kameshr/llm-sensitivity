{"nbformat": 4, "nbformat_minor": 0, "metadata": {"colab": {"provenance": [], "authorship_tag": "ABX9TyOzG2erxPh71vo2wkbAJGkw"}, "kernelspec": {"name": "python3", "display_name": "Python 3"}, "language_info": {"name": "python"}}, "cells": [{"cell_type": "code", "execution_count": null, "metadata": {"id": "n7As_GevXe1s"}, "outputs": [], "source": ["# ============================================================\n", "# 10) Save CSVs inside the repo\n", "# ============================================================\n", "OUTPUT_DIR = os.path.join(os.getcwd(), 'bitflip_outputs')\n", "os.makedirs(OUTPUT_DIR, exist_ok=True)\n", "\n", "# Per-trial CSV\n", "trial_path = os.path.join(OUTPUT_DIR, 'bitflip_per_trial.csv')\n", "df.to_csv(trial_path, index=False)\n", "print(f\"Saved per-trial CSV \u2192 {trial_path}\")\n", "\n", "# Aggregated CSV\n", "metric_cols = [c for c in [\n", "    \"EditDist\",\"EditDist_Norm\",\"BLEU\",\"METEOR\",\n", "    \"BERTScore_F1\",\"ROUGE1_F1\",\"ROUGE2_F1\",\"ROUGEL_F1\"\n", "] if c in df.columns]\n", "print(\"Aggregated metrics present:\", metric_cols)\n", "if metric_cols:\n", "    summary = df.groupby(\n", "        [\"rank\",\"tensor\",\"coord\",\"bit_class\",\"prompt\"],\n", "        as_index=False\n", "    ).agg({m: [\"mean\",\"median\",\"std\"] for m in metric_cols})\n", "    if isinstance(summary.columns, pd.MultiIndex):\n", "        summary.columns = [\"_\".join(filter(None, c)) for c in summary.columns]\n", "    agg_path = os.path.join(OUTPUT_DIR, 'bitflip_aggregated.csv')\n", "    summary.to_csv(agg_path, index=False)\n", "    print(f\"Saved aggregated CSV \u2192 {agg_path}\")\n", ""]}]}